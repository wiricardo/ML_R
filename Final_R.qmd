---
title: "Final_R"
subtitle: "ML_Models"
---

# Librerias a utilizar

```{r}
#| message: false
#| warning: false
library(tidymodels)
library(tidyverse)
library(dplyr)
library(rio)
library(naniar)
library(yardstick)
library(reshape2)
library(GGally)
```

# Seed para reproducibilidad

```{r}
set.seed(3500)
```

# Importacion de datos

```{r}

data <- import('Mall_Customers_Enhanced.csv')

```

# EDA

## Visualizamos la data

```{r}
head(data)
```

## Exploramos las variables

```{r}
str(data)
```

## Seleccionamos nuestras variables y nos aseguramos de que no haya datos faltantes

-   Nuestra variable objetivo será "Credit Score"
-   Nuestras variables predictoras serán: "Annual Income", "Preferred Category" y "Estimated savings"

```{r}
data |> select(`Credit Score`, `Annual Income (k$)`, `Preferred Category`, `Estimated Savings (k$)`) |> 
  filter(is.na(`Credit Score`))
```

## Revisamos que tampoco haya datos faltantes en nuetra variable objetivo (**Credit Score**)

```{r}
data |> filter(is.na(`Credit Score`))
```

## Ultima verificacion de datos faltantes

```{r}
data |> vis_miss()
```

## Exploramos las variables que escogimos

```{r}

est_vars <- summary(data |> select(`Credit Score`, `Annual Income (k$)`, `Preferred Category`, `Estimated Savings (k$)`) |> 
  as_tibble(rownames = 'Estadístico'))

est_vars


```

Notamos que podemos normalizar algunas variables y convertir a variables dummy la variable categgeorica

# Prepamos la data antes de definir el modelo de regresión lineal

## Split de la data

```{r}

ds_split <- initial_split(data)
training_data <- training(ds_split)
testing_data <- testing(ds_split)
```

## Procesamiento de los datos

Creamos las *recetas*

-   Receta 1: Usamos solo **Annual Income (k\$)** como predictor

```{r}
receta_1 <- recipe(`Credit Score` ~ `Annual Income (k$)`, data = training_data) |> 
  step_normalize(`Annual Income (k$)`)
```

-   Receta 2: Usamos **Annual Income (k\$)** y **Estimated Savings (k\$)** como predictores

```{r}
receta_2 <- recipe(`Credit Score` ~ `Annual Income (k$)` + `Estimated Savings (k$)`, data = training_data) |> 
  step_normalize(`Annual Income (k$)`, `Estimated Savings (k$)`)
```

-   Receta 3: Usamos **Annual Income (k\$)**, **Estimated Savings (k\$)** y **`Preferred Category`**(*variable categórica*) como predictores

```{r}
receta_3 <- recipe(`Credit Score` ~ `Annual Income (k$)` + `Estimated Savings (k$)` + `Preferred Category`, data = training_data) |> 
  step_normalize(`Annual Income (k$)`, `Estimated Savings (k$)`) |> 
  step_dummy(`Preferred Category`)
```

# Armamos el modelo de prediccion

## Definimos el modelo de prediccion: Regresion lineal

```{r}
reg_li <- linear_reg() |> 
                   set_engine("lm")
```

## Creamos Folds para cross validation

```{r}
folds <- vfold_cv(training_data, v= 4)
```

## Armamos los flujos

```{r}
flujo_1<-workflow() |> 
            add_recipe(receta_1) |> 
             add_model(reg_li)

flujo_2<-workflow() |> 
            add_recipe(receta_2) |> 
             add_model(reg_li)

flujo_3<-workflow() |> 
            add_recipe(receta_3) |> 
             add_model(reg_li)
```

## Cross Validation

```{r}

cv_flujo_1 <- flujo_1 |> fit_resamples(resamples = folds)
cv_flujo_2 <- flujo_2 |> fit_resamples(resamples = folds)
cv_flujo_3 <- flujo_3 |> fit_resamples(resamples = folds)

```

### Metricas

-   Modelo 1

```{r}
m1_cv <- cv_flujo_1 |> collect_metrics()
m1_cv
```

-   Modelo 2

```{r}
m2_cv <- cv_flujo_2 |> collect_metrics()
m2_cv
```

-   Modelo 3

```{r}
m3_cv <- cv_flujo_3 |> collect_metrics()
m3_cv
```

## Entrenamos los modelos

```{r}
modelo_1 <- flujo_1 |> fit(data = training_data)
modelo_2 <- flujo_2 |> fit(data = training_data)
modelo_3 <- flujo_3 |> fit(data = training_data)
```

### Coeficientes de los modelos

-   Modelo 1

```{r}
tidy(modelo_1)
```

-   Modelo 2

```{r}
tidy(modelo_2)
```

-   Modelo 3

```{r}
tidy(modelo_3)
```

# Evaluación de los modelos

-   Modelo 1

```{r}
m1_test <- modelo_1 |> predict(testing_data) |> bind_cols(valor_real = testing_data$`Credit Score`)

m1_metrics <- bind_rows(rmse(m1_test,
    truth = valor_real,
    estimate = .pred),
rsq(m1_test,
    truth = valor_real,
    estimate = .pred))
m1_metrics

```

```{r}
m1_plot <- m1_test |> 
  ggplot()+
  aes(x = valor_real, y = .pred)+
  geom_point(color = "blue", size = 2) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") + 
  labs(
    x = "Valor real",
    y = "Valor predicho",
    title = "Valores reales vs predicciones"
  ) +
  theme_minimal()

m1_plot
```

-   Modelo 2

```{r}
m2_test <- modelo_2 |> predict(testing_data) |> bind_cols(valor_real = testing_data$`Credit Score`)

m2_metrics <- bind_rows(rmse(m2_test,
    truth = valor_real,
    estimate = .pred),
rsq(m2_test,
    truth = valor_real,
    estimate = .pred))
m2_metrics
```

```{r}
m2_plot <- m2_test |> 
  ggplot()+
  aes(x = valor_real, y = .pred)+
  geom_point(color = "blue", size = 2) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") + 
  labs(
    x = "Valor real",
    y = "Valor predicho",
    title = "Valores reales vs predicciones"
  ) +
  theme_minimal()

m2_plot
```

-   Modelo 3

```{r}
m3_test <- modelo_3 |> predict(testing_data) |> bind_cols(valor_real = testing_data$`Credit Score`)

m3_metrics <- bind_rows(rmse(m3_test,
    truth = valor_real,
    estimate = .pred),
rsq(m3_test,
    truth = valor_real,
    estimate = .pred))
m3_metrics
```

```{r}
m3_plot <- m3_test |> 
  ggplot()+
  aes(x = valor_real, y = .pred)+
  geom_point(color = "blue", size = 2) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") + 
  labs(
    x = "Valor real",
    y = "Valor predicho",
    title = "Valores reales vs predicciones"
  ) +
  theme_minimal()

m2_plot
```

# Conclusiones Regresion Lineal

-   El modelo 3 fue el que mejor desempeño tuvo, sim embargo, no los suficiente como para lograr una buena prediccion
-   Se utilizó un modelo de regresión lineal por su simplicidad e interpretabilidad. Sin embargo, su desempeño fue limitado debido a la colinealidad entre predictores y a la no linealidad en las relaciones con la variable objetivo.

## Revisamos las correlaciones entre variables para identificar posible multicolinealidad

```{r}

cor_mat <- data |> 
  mutate(`Preferred Category` = as.numeric(as.factor(`Preferred Category`))) |> 
  select(`Credit Score`, `Annual Income (k$)`, `Preferred Category`, `Estimated Savings (k$)`) |> 
  cor() |> round(2)

melted_cormat <- melt(cor_mat)
head(melted_cormat)
```

### Heatmap para mejor identificación

```{r}
cor_mat_plot <- ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
 scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab") +
  theme_minimal()+ 
 theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 12, hjust = 1)) +
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 4)

cor_mat_plot
```

-   Annual Income y Estimated Savings tienen multicolinealidad alta (0.81), lo que significa información redundante.

## Verificamos la linealidad de los datos

```{r}
lin_data <- data |> 
  mutate(`Preferred Category` = as.numeric(as.factor(`Preferred Category`))) |> 
  select(`Credit Score`, `Annual Income (k$)`, `Preferred Category`, `Estimated Savings (k$)`)
```

### Scatter plot para facilitar la visualizacion

```{r}
lin_plot <- ggpairs(lin_data)
lin_plot
```

-   Credit Score, Annual Income y Estimated Savings muestran relaciones lineales positivas.

-   Annual Income y Estimated Savings son las más fuertemente lineales.

-   Credit Score también crece linealmente con Annual Income y Estimated Savings, aunque con curvatura en valores altos.

-   Preferred Category no presenta linealidad, pues es una variable categórica codificada.

# Alternativa a Regresion Lineal

## Ramdom Forest

### Entrenamiento

```{r}
modelo_rf <- rand_forest(trees = 500, mtry = 5, min_n = 10) |>
  set_engine("ranger") |>
  set_mode("regression")

flujo_rf <- workflow() |>
  add_recipe(receta_3) |>
  add_model(modelo_rf)

cv_rf <- fit_resamples(flujo_rf, resamples = folds, metrics = metric_set(rmse, rsq))
collect_metrics(cv_rf)

```

### Testeo

```{r}
fit_rf <- fit(flujo_rf, data = training_data)

rf_test <- augment(fit_rf, new_data = testing_data)

rf_metrics <- metric_set(rmse, rsq)(rf_test, truth = `Credit Score`, estimate = .pred)
rf_metrics
```

```{r}

rf_plot <- ggplot(rf_test, aes(x = `Credit Score`, y = .pred)) +
  geom_point(color = "blue", size = 2) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
  labs(
    title = "Random Forest: Valores reales vs predichos",
    x = "Valor real (Credit Score)",
    y = "Valor predicho"
  ) +
  theme_minimal()

rf_plot
```

### Conclusiones

-   El modelo de Random Forest alcanzó un mejor rendimiento, con un coeficiente de determinación (R²) de 0.94 y un error cuadrático medio (RMSE) de aproximadamente 40, lo que reduce significativamente el error en comparación con la regresión lineal.

### Guardado de plots

```{r}
saveRDS(m1_plot, file = "m1_plot.rds")
saveRDS(m2_plot, file = "m2_plot.rds")
saveRDS(m3_plot, file = "m3_plot.rds")
saveRDS(rf_plot, file = "rf_plot.rds")

```

### Guardado de metricas de modelos

Modelos iniciales

```{r}
saveRDS(m1_metrics, file = "m1_metrics.rds")
saveRDS(m2_metrics, file = "m2_metrics.rds")
saveRDS(m3_metrics, file = "m3_metrics.rds")
saveRDS(rf_metrics, file = "rf_metrics.rds")
```
